{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n",
    "from fastai import metrics\n",
    "import pandas as pd\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class MixedInputModel(nn.Module):\n",
    "    def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                 y_range=None, use_bn=False):\n",
    "        super().__init__()\n",
    "        self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])\n",
    "        for emb in self.embs: emb_init(emb)\n",
    "        n_emb = sum(e.embedding_dim for e in self.embs)\n",
    "        self.n_emb, self.n_cont=n_emb, n_cont\n",
    "        \n",
    "        szs = [n_emb+n_cont] + szs\n",
    "        self.lins = nn.ModuleList([\n",
    "            nn.Linear(szs[i], szs[i+1]) for i in range(len(szs)-1)])\n",
    "        self.bns = nn.ModuleList([\n",
    "            nn.BatchNorm1d(sz) for sz in szs[1:]])\n",
    "        for o in self.lins: kaiming_normal(o.weight.data)\n",
    "        self.outp = nn.Linear(szs[-1], out_sz)\n",
    "        kaiming_normal(self.outp.weight.data)\n",
    "\n",
    "        self.emb_drop = nn.Dropout(emb_drop)\n",
    "        self.drops = nn.ModuleList([nn.Dropout(drop) for drop in drops])\n",
    "        self.bn = nn.BatchNorm1d(n_cont)\n",
    "        self.use_bn,self.y_range = use_bn,y_range\n",
    "\n",
    "    def forward(self, x_cat, x_cont):\n",
    "        if self.n_emb != 0:\n",
    "            x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]\n",
    "            x = torch.cat(x, 1)\n",
    "            x = self.emb_drop(x)\n",
    "        if self.n_cont != 0:\n",
    "            x2 = self.bn(x_cont)\n",
    "            x = torch.cat([x, x2], 1) if self.n_emb != 0 else x2\n",
    "        for l,d,b in zip(self.lins, self.drops, self.bns):\n",
    "            x = F.relu(l(x))\n",
    "            if self.use_bn: x = b(x)\n",
    "            x = d(x)\n",
    "        x = self.outp(x)\n",
    "        if self.y_range:\n",
    "            x = F.sigmoid(x)\n",
    "            x = x*(self.y_range[1] - self.y_range[0])\n",
    "            x = x+self.y_range[0]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnarDataset(Dataset):\n",
    "    def __init__(self, cats, conts, y):\n",
    "        n = len(cats[0]) if cats else len(conts[0])\n",
    "        self.cats = np.stack(cats, 1).astype(np.int64) if cats else np.zeros((n,1))\n",
    "        self.conts = np.stack(conts, 1).astype(np.float32) if conts else np.zeros((n,1))\n",
    "        self.y = np.zeros((n,1)) if y is None else y.values # THIS LINE IS CHANGED FROM y[:, None]\n",
    "        \n",
    "    def __len__(self): return len(self.y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.cats[idx], self.conts[idx], self.y[idx]]\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, df_cat, df_cont, y=None):\n",
    "        cat_cols = [c.values for n,c in df_cat.items()]\n",
    "        cont_cols = [c.values for n,c in df_cont.items()]\n",
    "        return cls(cat_cols, cont_cols, y)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, df, cat_flds, y=None):\n",
    "        return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class ColumnarModelData(ModelData):\n",
    "    def __init__(self, path, trn_ds, val_ds, bs=None, ts_bs=None,  sampler=None, test_ds=None, shuffle=None): ## add batch_sampler\n",
    "        test_dl = DataLoader(test_ds, ts_bs, shuffle=False, num_workers=1) if test_ds is not None else None\n",
    "        super().__init__(path, DataLoader(trn_ds, batch_size=bs, sampler=sampler, shuffle=shuffle, num_workers=1),\n",
    "            DataLoader(val_ds, bs, shuffle=False, num_workers=1), test_dl)\n",
    "\n",
    "    @classmethod\n",
    "    def from_arrays(cls, path, val_idxs, xs, y, bs=None, ts_bs=None, sampler=None, test_xs=None, shuffle=True):\n",
    "        ((val_xs, trn_xs), (val_y, trn_y)) = split_by_idx(val_idxs, xs, y)\n",
    "        test_ds = PassthruDataset(*(test_xs.T), [0] * len(test_xs)) if test_xs is not None else None\n",
    "        return cls(path, PassthruDataset(*(trn_xs.T), trn_y), PassthruDataset(*(val_xs.T), val_y),\n",
    "                   bs, shuffle=shuffle, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs=None, ts_bs=None, sampler=None, test_df=None):\n",
    "        test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds) if test_df is not None else None\n",
    "        return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y),\n",
    "                    ColumnarDataset.from_data_frame(val_df, cat_flds, val_y), bs, sampler=sampler, test_ds=test_ds)\n",
    "\n",
    "    @classmethod\n",
    "    def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs=None,  ts_bs=None, sampler=None, test_df=None):\n",
    "        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)\n",
    "        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, sampler=sampler, test_df=test_df)\n",
    "\n",
    "    def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,\n",
    "                    y_range=None, use_bn=False, **kwargs):\n",
    "        model = MixedInputModel(emb_szs, n_cont, emb_drop, out_sz, szs, drops, y_range, use_bn)\n",
    "        return StructuredLearner(self, StructuredModel(to_gpu(model)), opt_fn=optim.Adam, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path='/home/paperspace/data/talkingdata/'\n",
    "dtypes = {\n",
    "        'ip'            : 'uint32',\n",
    "        'app'           : 'uint16',\n",
    "        'device'        : 'uint16',\n",
    "        'os'            : 'uint16',\n",
    "        'channel'       : 'uint16',\n",
    "        'is_attributed' : 'uint8',\n",
    "        'click_id'      : 'uint32'\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_feather(f'{path}train_df')\n",
    "test_df = pd.read_feather(f'{path}test_df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000000"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_vars =['app', 'channel', 'device', 'ip'\n",
    "           , 'os', 'hour', 'day', 'wday', 'qty', 'ip_app_count',\n",
    "       'ip_app_os_count']\n",
    "dep = 'is_attributed'\n",
    "n = len(train_df); n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df[cat_vars+[dep]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for v in cat_vars: train_df[v] = train_df[v].astype('category').cat.as_ordered()\n",
    "for v in cat_vars: test_df[v] = test_df[v].astype('category').cat.as_ordered()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/mynb/talkingdata/fastai/structured.py:198: RuntimeWarning: None of the categories were found in values. Did you mean to use\n",
      "'Categorical.from_codes(codes, categories)'?\n",
      "  df[n] = pd.Categorical(c, categories=trn[n].cat.categories, ordered=True)\n"
     ]
    }
   ],
   "source": [
    "apply_cats(test_df, train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = train_df.reset_index(drop=True)\n",
    "test_df = test_df.reset_index(drop=True)\n",
    "test_df[['click_id']] = test_df[['click_id']].astype(\"int32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs = get_cv_idxs(n, val_pct=0.001)\n",
    "train_df_samp = train_df.iloc[idxs]\n",
    "samp_size = len(train_df_samp); samp_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(train_df[c].cat.categories)+1) for c in cat_vars]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df, y, nas = proc_df(train_df_samp, 'is_attributed', do_scale=False)\n",
    "del train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_test, y_test, nas = proc_df(test_df[cat_vars+[dep]], 'is_attributed', do_scale=False)\n",
    "del test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "351"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.002575"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_pct =np.sum(y==1)/len(y)\n",
    "one_pct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_idx = list(range(round(len(df)*0.8), len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trn_y = np.delete(y, val_idx)\n",
    "weights = np.zeros(len(trn_y))\n",
    "\n",
    "for i in range(len(trn_y)):\n",
    "    if(trn_y[i]==1):\n",
    "        weights[i] = 1\n",
    "    else:\n",
    "        weights[i] = 0.1\n",
    "del trn_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(path, val_idx, df, pd.Series(y.astype('int')), cat_flds=cat_vars,bs=128*2, ts_bs=128,\n",
    "                                       sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(weights)),\n",
    "                                       test_df = df_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# weighted sample see flag\n",
    "#next(iter(md.trn_dl))[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_szs = [(c, max(50, round(500*(1/c)))) for _,c in cat_sz]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = MixedInputModel(emb_szs, n_cont=0, emb_drop=0.1, out_sz=2, szs=[1000, 500, 100], drops=[0.1, 0.1, 0.1]).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bm = BasicModel(model, 'binary_classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# you can simply create learner with any custom model and data\n",
    "# source code is here\n",
    "class StructuredLearner(Learner):\n",
    "    def __init__(self, data, models, **kwargs):\n",
    "        super().__init__(data, models, **kwargs)\n",
    "        self.crit = F.mse_loss\n",
    "\n",
    "\n",
    "learn = StructuredLearner(md, bm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function torch.nn.functional.cross_entropy>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note that we've changed the model class' crit attribute\n",
    "# this is not recommended from an OOP perspective \n",
    "# but it's handy here\n",
    "learn.crit = F.cross_entropy\n",
    "learn.crit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e17d40248e3440c483adc87405adbfa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      0.207456   35.510422 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learn.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'plot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-14f0a0eeb10b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'plot'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb4d08b6bf5141618789794f998eada4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      0.132066   0.030631  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.030631274]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 0.01\n",
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.save('mod_rs_1e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learn.load('mod_rs_1e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9771188565697092"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.metrics.roc_auc_score(y[val_idx], learn.predict()[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr = 0.01*0.1\n",
    "learn.fit(lr, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.save('mod_4_4e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#learn.load('mod_4_3e')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sklearn.metrics.roc_auc_score(y[val_idx], learn.predict()[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## if memory runs out, delete dataloader object (md), create only test_dl.\n",
    "## in the future, should ve create separate dataloader for train and valid, and test sets.\n",
    "\n",
    "pred = learn.predict_dl(md.test_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i_batch, sample_batched in \n",
    "enumerate(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# softmax\n",
    "expsums = np.exp(preds).sum(axis=1)\n",
    "probs = np.exp(preds) / expsums[:, None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df['is_attributed'] = probs[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub = test_df[['click_id','is_attributed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sub.to_csv('/home/paperspace/data/talkingdata/sub/'+\"sub_dp_6.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
